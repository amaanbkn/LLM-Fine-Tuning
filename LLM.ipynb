{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvt7TNRrz-Kz",
        "outputId": "887aaaa3-518e-4173-f52a-327cfb36d432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.11.1-py3-none-any.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/61.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo>=2025.11.1 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.11.2-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
            "Collecting datasets!=4.0.*,!=4.1.0,>=3.4.1 (from unsloth)\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.11.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.17.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.1)\n",
            "Collecting trl!=0.19.0,<=0.23.0,>=0.18.2 (from unsloth)\n",
            "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.20.0)\n",
            "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (0.22.1)\n",
            "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.1->unsloth)\n",
            "  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.11.1->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.1->unsloth) (11.3.0)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.11.1->unsloth)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.13.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.3.1)\n",
            "Downloading unsloth-2025.11.1-py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m348.8/348.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.11.2-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m134.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchao, shtab, pyarrow, msgspec, tyro, xformers, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: torchao\n",
            "    Found existing installation: torchao 0.10.0\n",
            "    Uninstalling torchao-0.10.0:\n",
            "      Successfully uninstalled torchao-0.10.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.4.1 msgspec-0.19.0 pyarrow-22.0.0 shtab-1.7.2 torchao-0.14.1 trl-0.23.0 tyro-0.9.35 unsloth-2025.11.1 unsloth_zoo-2025.11.2 xformers-0.0.32.post2\n"
          ]
        }
      ],
      "source": [
        "pip install unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMV2dDE-0EC4",
        "outputId": "f975bc0d-a6c3-43b8-ec51-f6da3dc10e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL8RVjzn0RT0"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 2048 # Choose any! Unsloth also supports RoPE (Rotary Positinal Embedding) scaling internally.\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "3b3408b8d0094c13806eb013546feb63",
            "c77358f4288949a2970e1dc6d84c83ff",
            "5bf6229dd7684671bdd8443e13f50fdb",
            "f84d25e553c14558b095f43df16b9c53",
            "c8141b72df7f4647bee99ec7fd6b9309",
            "d4603f95ccae44b4b18a12d67177919f",
            "1eb34896912943a48db5f96bc3fe0055",
            "11e7a7afc9414217abb1e4c9a072fc02",
            "7771ce0c51c047b697c993213e1682cf",
            "7a53f17f4f494aa8bdb454ddf80f0ead",
            "bae1e451485144e9820982957e2be6c1",
            "12f1dd7726c647778108c3e35ad85dfa",
            "15e9d71376f14aec9b11c0a8ce8ae1b6",
            "f2e9a966be9646d28ae3daef30ddc871",
            "5bfd8093101e419f91a7cbf093bfb3f0",
            "5a8b3e9bfe2e4742ab216d9ae72b4178",
            "6c712ed7c67c4758a80f66ab1363bae5",
            "f0a26d46167e40eeb4e53357569c7897",
            "813da3943e744ac9b3879347b28603c3",
            "fbff45c6a5d54780b317ed875a7a5c39",
            "138813a454a746b490a75d5bac1ccbdb",
            "50392b79b2b04b7cb51923d9a10d8447",
            "8092d7f443d44f0c9216f50e5e4faecc",
            "6a35a46413c349188eb5988ddf0c5b20",
            "e6bc064f7eee426ab0322a65562facb3",
            "f01419778c5c47c09d98b00021079584",
            "8337b285010a42e1895c479c6c71a03b",
            "9596b8a03d974a75be54f449ecb964a3",
            "91415d45c2b440c09503d76dc5c50144",
            "e7bc949e39324a17b518ac048a27b86a",
            "14bf675ce8cd49ae9d496c411e0273bc",
            "b5eec52a19c5444da3b0b3452f633483",
            "9204f0e5d72040ff8e60adbf4507f6f9",
            "b62045daafdc4f00bf4fc772931de37c",
            "0872433b1937431d9abee385bfbf9a37",
            "37bfacb0b7b245e599f8efad4eb3247e",
            "4ffd43ed97ac4872a575a4b232f9d272",
            "352f83ab794744aea91a65daa98d6a62",
            "8da5020ce3e34cde8d3e3955987b1b60",
            "37aa28340d484aaaa32205243742e50e",
            "69e9e830eca24ed59ef44e2449307f42",
            "788eaafd1b604e9383123f43678a9079",
            "5126f829c24744a0b989f2d1dfd2b0f0",
            "52f0c117b988485f96b2120c20d379bb",
            "328b677a6d03459e9cf789dbdb0df181",
            "3ed6aed7462b4c7d8123cf2a9204b67e",
            "1ff7bc24d04e446faec48a983a5e2d74",
            "71abfed465bf4e7b80377b2ce43d8de8",
            "31eb562b1aca48debf6a3a6f1e9fc114",
            "acba8f784af943ad89868f08218be42b",
            "1933136fbf4c478daf7bd19d6122c449",
            "a17e01a9640d4a55a6d8a1a21acef951",
            "48dcaba71f8d4e90af926e22d240fa7f",
            "952cfac0fb094311a0d68b0ed35a5758",
            "6bec29390c53486fa0627e5e03689db4",
            "1d8819243bc04d74962bddc1b10e907c",
            "39e9a96dc76f47a2bbbb91245425924e",
            "b2d276b112f54a6a81fe667573b23fef",
            "3fab86c005bf4f3fbb68d987d51cc0e4",
            "9511ecbd67324860a1324d7f979b88a8",
            "9e444a73800e4dcf82e1cd21b9468399",
            "54a96939f9214ece8bf5082f53e7f8e9",
            "4e9c0450f8074b4f9839dba83a10d15b",
            "f797ba9160d64846bcd0bb98934f2931",
            "69a2dbdbb1a94e71804a82f575d4c6a6",
            "5bf5b0083634472d84d5ffd7f779b950"
          ]
        },
        "id": "kfqpC8vB0fzg",
        "outputId": "5535c959-e220-4c1d-bf8f-184fd305dc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.11.1: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b3408b8d0094c13806eb013546feb63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12f1dd7726c647778108c3e35ad85dfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8092d7f443d44f0c9216f50e5e4faecc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b62045daafdc4f00bf4fc772931de37c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "328b677a6d03459e9cf789dbdb0df181",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d8819243bc04d74962bddc1b10e907c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "chat_template.jinja: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit, # Will load the 4Bit Quantized Model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4naiH7zr0hrn",
        "outputId": "a4477f67-be53-4699-f51c-c0ae887e8fb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.11.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16, # a higher alpha value assigns more weight to the LoRA activations\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "f9deb39cdcf84d3f8eba6578bdb76993",
            "78ef3d56ef0c407f8562459d71856e88",
            "db774cc038c04cd7b3cfbf24c4b6c42c",
            "50713f33e770412a8937e62aa152d69e",
            "f45332634a5b467cb2d08c20dd1845ea",
            "2fb60824bfcd4634bcd3ff48f8cd7263",
            "88471adb55e84c46940d3ef4c8094ab7",
            "5611f005aaed4bd688fb419c91f17980",
            "c90efbddf1af48729882fba6bcff29fe",
            "32f35b4e834b4acb86a56e2ce957ca11",
            "c2d77d50329848d18af57dfc097c4f63",
            "ab7f868ec59a4c66b374681c9a6d13b9",
            "ea607758bc454681b5939d5e153e9303",
            "03922f4ee394418881abe93349ebf744",
            "8229e25f762c4273b1fc550953038fc1",
            "20d2fc0bcd5949eeb98014fc4bef08f7",
            "cafc2ea393df44809ccd2049290d9289",
            "c23d21959e0044af92df4deeaec1f70b",
            "6f4f58c4dcde4893a3fa53dd99e9f489",
            "cb9ba493c16c4199b6f198be28318ad4",
            "90fbf975d0c14a03b69846090b587ac0",
            "0aa19d816dae4ca8ace71bb48b29292f",
            "1f0ddaff1c00464d871fdc53298c6395",
            "7eb63858df2949f1b352b2182e3b1ed7",
            "1ac0fab4a9504ab0874c5e6aeb7d72ad",
            "a5afaa0a66c24b93aa04159168519d8b",
            "474c7f81d38442a99026e8057576af7b",
            "c9b91a549ea249c59a7503b801ec1957",
            "0d4ba81c321e4fa08c176e1041181b83",
            "25b7e5655f64445094462867991aaaaf",
            "e8aaf947ccfa4769b1e809d05346416b",
            "10eda1b53c6340fd9122b68d5470fb7e",
            "ab9d2277f9ea4a6881ee1de0072eeda1",
            "f908f55336f94badb6b6e4379e5560eb",
            "03c6778d26cd43e29bf32fb7991bca4c",
            "1588eb58b63c4e1e9191e9c21d11439d",
            "44adaa3f0b1e4aed93958de531f16d28",
            "adfe85dd5777496eb43a2546c984e013",
            "4ca5392118a048bd9f3b211d728a13ae",
            "25cb56938f8c45098de0bd0f69e08a26",
            "22a599e9570c4b058f06ed0aa219ad40",
            "8cff763010704adb8226f8a9deafa5c0",
            "6022a874fe1b45c68371519fd6829c11",
            "16b1222f18574ebfa4b43333ecc44509",
            "265010694bca4011bde23b3426b2b7f7",
            "fa98df70a3824c319230d44af3ae60f6",
            "145b69ba59df444a9f6378aab39cadc0",
            "190d0ffda5644b018404b878ef52ad8f",
            "4d0cff74c6a14799a7cd96fcc1a33b75",
            "cda00c0c2d234df38f9eae036ba86963",
            "eef463e6fb0243f6b81caf92aa6caaf1",
            "75af9764c75d4cea941c2f300a1e73f5",
            "9a0fa1e04e8348abbb27c503a2c31322",
            "77034918d72343aeaffdb465948d3302",
            "9782a2158eaf492b8132b240f38d51b4"
          ]
        },
        "id": "ysF-NOXh020Q",
        "outputId": "517ec71c-1150-40a8-89c2-25bf7de25e02"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9deb39cdcf84d3f8eba6578bdb76993",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab7f868ec59a4c66b374681c9a6d13b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "v0/train-00000-of-00003.parquet:   0%|          | 0.00/180M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f0ddaff1c00464d871fdc53298c6395",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "v0/train-00001-of-00003.parquet:   0%|          | 0.00/187M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f908f55336f94badb6b6e4379e5560eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "v0/train-00002-of-00003.parquet:   0%|          | 0.00/188M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "265010694bca4011bde23b3426b2b7f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/171647 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"ServiceNow-AI/R1-Distill-SFT\",'v0', split = \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb-s_DHZ0221",
        "outputId": "236087f2-eafc-43e7-862d-d862a238ef2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': ['id_0', 'id_1', 'id_2', 'id_3', 'id_4'], 'reannotated_assistant_content': ['<think>\\nFirst, I need to determine the total number of children on the playground by adding the number of boys and girls.\\n\\nThere are 27 boys and 35 girls.\\n\\nAdding these together: 27 boys + 35 girls = 62 children.\\n\\nTherefore, the total number of children on the playground is 62.\\n</think>\\n\\nTo find the total number of children on the playground, we simply add the number of boys and girls together.\\n\\n\\\\[\\n\\\\text{Total children} = \\\\text{Number of boys} + \\\\text{Number of girls}\\n\\\\]\\n\\nPlugging in the given values:\\n\\n\\\\[\\n\\\\text{Total children} = 27 \\\\text{ boys} + 35 \\\\text{ girls} = 62 \\\\text{ children}\\n\\\\]\\n\\n**Final Answer:**\\n\\n\\\\[\\n\\\\boxed{62}\\n\\\\]', '<think>\\nFirst, I need to determine the cost per dozen oranges. John bought three dozen oranges for \\\\$28.80, so I can find the cost per dozen by dividing the total cost by the number of dozens.\\n\\nNext, with the cost per dozen known, I can calculate the cost for five dozen oranges by multiplying the cost per dozen by five.\\n\\nFinally, I will present the final answer clearly.\\n</think>\\n\\n**Solution:**\\n\\nTo determine the cost of five dozen oranges at the same rate, follow these steps:\\n\\n1. **Find the cost per dozen:**\\n\\n   John purchased three dozen oranges for \\\\$28.80. To find the cost per dozen, divide the total cost by the number of dozens.\\n\\n   \\\\[\\n   \\\\text{Cost per dozen} = \\\\frac{\\\\$28.80}{3} = \\\\$9.60 \\\\text{ per dozen}\\n   \\\\]\\n\\n2. **Calculate the cost for five dozen:**\\n\\n   Now, multiply the cost per dozen by the number of dozens needed.\\n\\n   \\\\[\\n   \\\\text{Cost for five dozen} = 5 \\\\times \\\\$9.60 = \\\\$48.00\\n   \\\\]\\n\\n3. **Final Answer:**\\n\\n   \\\\[\\n   \\\\boxed{\\\\$48}\\n   \\\\]', '<think>\\nFirst, determine how many bags Bianca actually recycled by subtracting the number of bags she did not recycle from the total number of bags she had.\\n\\nThen, calculate the total points she earned by multiplying the number of recycled bags by the points earned per bag.\\n</think>\\n\\n**Solution:**\\n\\n1. **Determine the number of bags Bianca recycled:**\\n\\n   Bianca had a total of 17 bags but did not recycle 8 of them. Therefore, the number of bags she actually recycled is:\\n   \\n   \\\\[\\n   17 \\\\text{ bags} - 8 \\\\text{ bags} = 9 \\\\text{ bags}\\n   \\\\]\\n\\n2. **Calculate the total points earned:**\\n\\n   Bianca earns 5 points for each bag she recycles. For 9 bags, the total points earned are:\\n   \\n   \\\\[\\n   9 \\\\text{ bags} \\\\times 5 \\\\text{ points/bag} = 45 \\\\text{ points}\\n   \\\\]\\n\\n**Final Answer:**\\n\\n\\\\[\\n\\\\boxed{45}\\n\\\\]', '<think>\\nFirst, identify the cost of one bottle cap, which is $2.\\n\\nNext, determine the number of bottle caps needed, which is 6.\\n\\nMultiply the cost per bottle cap by the number of bottle caps: 6 \u00d7 $2 = $12.\\n\\nTherefore, the total cost for 6 bottle caps is $12.\\n</think>\\n\\nTo determine the total cost of 6 bottle caps, follow these easy steps:\\n\\n1. **Identify the cost per bottle cap:**\\n   \\n   Each bottle cap costs \\\\$2.\\n\\n2. **Determine the number of bottle caps:**\\n   \\n   You need 6 bottle caps.\\n\\n3. **Calculate the total cost:**\\n   \\n   \\\\[\\n   \\\\text{Total Cost} = \\\\text{Number of Bottle Caps} \\\\times \\\\text{Cost per Bottle Cap}\\n   \\\\]\\n   \\n   \\\\[\\n   \\\\text{Total Cost} = 6 \\\\times \\\\$2 = \\\\$12\\n   \\\\]\\n\\n4. **Final Answer:**\\n   \\n   \\\\[\\n   \\\\boxed{\\\\$12}\\n   \\\\]', \"<think>\\nFirst, I need to determine how many emails Jack received in the afternoon.\\n\\nI know that Jack received 6 emails in the morning.\\n\\nIt is also given that he received 2 more emails in the afternoon than in the morning.\\n\\nTo find the total number of emails received in the afternoon, I will add the number of emails received in the morning to the additional 2 emails.\\n\\nSo, 6 emails (morning) + 2 emails = 8 emails.\\n\\nTherefore, Jack received 8 emails in the afternoon.\\n</think>\\n\\n**Solution:**\\n\\nLet's determine how many emails Jack received in the afternoon.\\n\\n1. **Emails in the Morning:**\\n   \\n   Jack received **6 emails** in the morning.\\n\\n2. **Additional Emails in the Afternoon:**\\n   \\n   He received **2 more emails** in the afternoon than in the morning.\\n\\n3. **Calculating Afternoon Emails:**\\n   \\n   \\\\[\\n   \\\\text{Afternoon Emails} = \\\\text{Morning Emails} + 2 = 6 + 2 = 8\\n   \\\\]\\n\\n**Final Answer:**\\n\\nJack received \\\\(\\\\boxed{8}\\\\) emails in the afternoon.\"], 'problem': ['There were 27 boys and 35 girls on the playground at recess. There were _____ children on the playground at recess.', 'John purchased three dozen oranges for $\\\\$$28.80. At the same rate, how much would five dozen of these oranges cost?', \"Bianca earned 5 points for each bag of cans she recycled. If she had 17 bags, but didn't recycle 8 of them, how many points would she have earned?\", 'Each bottle cap costs $2. How much do 6 bottle caps cost?', 'Jack received 6 emails in the morning and some emails in the afternoon. He received 2 more emails in the afternoon than in the morning. How many emails did Jack receive in the afternoon?'], 'source': ['orca_math', 'synthetic_math', 'orca_math', 'orca_math', 'orca_math'], 'solution': ['\\nThere were 62 children on the playground at recess. (27 boys + 35 girls = $\\\\boxed{62}$  children)', 'The problem states that John bought three dozen oranges for $\\\\$$28.80. To find the cost per dozen, we use the formula:\\n$$ \\\\text{Cost per dozen} = \\\\frac{\\\\text{Total cost}}{\\\\text{Number of dozens}} = \\\\frac{\\\\$28.80}{3} = \\\\$9.60 \\\\text{ per dozen}. $$\\n\\nTo determine the cost for five dozen oranges:\\n$$ \\\\text{Cost for five dozen} = 5 \\\\times \\\\text{Cost per dozen} = 5 \\\\times \\\\$9.60 = \\\\$48. $$\\n\\nThus, the cost for five dozen oranges is $\\\\boxed{\\\\$48}$.', 'Bianca recycled 17 - 8 = 9 bags of cans.\\n\\nFor each bag of cans, she earned 5 points, so for 9 bags, she would have earned 9 * 5 = $\\\\boxed{45}$  points.', '\\nIf each bottle cap costs $2, then 6 bottle caps would cost 6 x $2 = $\\\\boxed{\\\\$12}$ .', '\\nIf Jack received 6 emails in the morning and he received 2 more emails in the afternoon than in the morning, then he received 6 + 2 = $\\\\boxed{8}$  emails in the afternoon.'], 'verified': [None, None, None, None, None], 'quality_metrics': [None, None, None, None, None]}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbtpV5LZ1u5_"
      },
      "outputs": [],
      "source": [
        "r1_prompt = \"\"\"You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n",
        "<problem>\n",
        "{}\n",
        "</problem>\n",
        "\n",
        "{}\n",
        "{}\n",
        "\"\"\"\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "  problems = examples[\"problem\"]\n",
        "  thoughts = examples[\"reannotated_assistant_content\"]\n",
        "  solutions = examples[\"solution\"]\n",
        "  texts = []\n",
        "\n",
        "  for problem, thought, solution in zip(problems, thoughts, solutions):\n",
        "    text = r1_prompt.format(problem, thought, solution)+EOS_TOKEN\n",
        "    texts.append(text)\n",
        "\n",
        "  return texts # Return the list directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "50c6d82cbcb7461a9cad7e7a4cccde1b",
            "e5619840c7d5423692a9809f9af4747a",
            "4515aa2657a449b48c117c682185a571",
            "cbc4932b92cf417c92671157d8be5055",
            "a90cc52bcf9444f087e9d575b96950bb",
            "474c4dc196124e1491ecc10a05d87e42",
            "9f50d640ee814d77bf0df3212343b50d",
            "aab3d8de316e459ca240dc9426ec1eab",
            "77743e6fb7f44d03921d88f69bbb9db6",
            "ade89a900a6d42198472231b01cace06",
            "753bd277354740748d82066b563d33a7"
          ]
        },
        "id": "QIxNy6NP1yrC",
        "outputId": "983cc127-8053-4a3a-b45e-a459c0a8902c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50c6d82cbcb7461a9cad7e7a4cccde1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/171647 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    formatting_func = formatting_prompts_func, # Add this line\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2, # Number of processors to use for processing the dataset\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2, # The batch size per GPU/TPU core\n",
        "        gradient_accumulation_steps = 4, # Number of steps to perform befor each gradient accumulation\n",
        "        warmup_steps = 5, # Few updates with low learning rate before actual training\n",
        "        max_steps = 60, # Specifies the total number of training steps (batches) to run.\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\", # Optimizer\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc for observability\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nUXOPjpI2KAK",
        "outputId": "622f5d95-b8d6-4782-bd34-c43bfe8865db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 171,647 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 09:22, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.935000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.943900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.786000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.853500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.756500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.741500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.786500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.736700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.631700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.637200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.621100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.568000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.633000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.574300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.557600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.522600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.558900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.721500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.626400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.602500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.607700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.539600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.493400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.589300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.472300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.652200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.601900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.625500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.711600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.530900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.463700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.586200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.594600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.584800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.606300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.557400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.484900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.552900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.549200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.597100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.539100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.494000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.534500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.503400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.623600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.579600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.702500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.620500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.430200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.693200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.618000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.503500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tn280Nh7Zh9",
        "outputId": "a2fdfa28-8472-460b-b027-7a16648d1c48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "sys_prompt = \"\"\"You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n",
        "<problem>\n",
        "{}\n",
        "</problem>\n",
        "\"\"\"\n",
        "message = sys_prompt.format(\"How many 'r's are present in 'strawberry'?\")\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": message},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 1024, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "response = tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNWkLraW9vz5",
        "outputId": "6f254579-0c00-418e-c123-9f1486af0bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before coming up with an answer.\n",
            "<problem>\n",
            "How many 'r's are present in'strawberry'?\n",
            "</problem>\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Alright, let me figure out how many 'r's are in the word'strawberry'. Okay, so I remember that 'r' is the seventh letter of the alphabet, but is that correct? Let me just check again to make sure. In the standard English alphabet, 'r' is indeed the seventh letter, so that's probably correct.\n",
            "\n",
            "Okay, now, looking at'strawberry'. It's a seven-letter word. I need to count the number of 'r's in it. Let's break it down:\n",
            "\n",
            "- S: That's's'. No 'r's here.\n",
            "- T: That's 't'. Still no 'r'.\n",
            "- R: Hmm, there is a 'r' here. That's the second letter. Okay, so one 'r'.\n",
            "- A: 'a' doesn't have an 'r'. Nope.\n",
            "- W: That's 'w'. Still no 'r'.\n",
            "- B: 'b'. No 'r'.\n",
            "- E: 'e'. Not 'r'.\n",
            "\n",
            "Okay, so up to 'E', there's only one 'r'. Let me continue:\n",
            "\n",
            "- R: Second 'r'. Wait, let's not count twice. Let me see if it repeats. So,'s', 't', 'r', 'a', 'w', 'b', 'e', and then the final 'r' appears in 'berry'. So, it seems like 'r' only appears twice.\n",
            "\n",
            "Let me double-check. From's' to the last 'r' in 'berry', there are indeed'straw' and 'berry'. In'straw', there's one 'r', and in 'berry', there's another. So, one in'straw', another in 'berry'. So, that's two.\n",
            "\n",
            "Yes, I'm pretty sure that's correct. Let me summarize:\n",
            "\n",
            "-'s' to 't': 5 letters, but no 'r'.\n",
            "- 't' to the next 'r': 5 letters, and the first 'r' appears here. That's 2 'r's so far: one from's', 't', and the second from 'r'.\n",
            "- 'r' to the next letters: 4 letters, none 'r'.\n",
            "- Next 'r' in 'berry': That's a different one.\n",
            "\n",
            "So, yes, that makes two. I don't see any other 'r's in'strawberry'. Maybe if I write it out:\n",
            "\n",
            "S-T-R-A-W-B-E-R-R-Y\n",
            "\n",
            "See? Two 'r's in there. So, definitely 2.\n",
            "\n",
            "I think I made sure to check carefully. If I was miscounting or misreading, I would probably get a different number. But no, one 'r' from the first part and another 'r' from 'berry'. That's two total. So, the answer is:\n",
            "\n",
            "2.\n",
            "\n",
            "I hope I got it right!<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "print(response[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LWkdAh_-93g",
        "outputId": "34a6e078-6241-44e4-b920-a5ce78543611"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('chintan-001-3B/tokenizer_config.json',\n",
              " 'chintan-001-3B/special_tokens_map.json',\n",
              " 'chintan-001-3B/chat_template.jinja',\n",
              " 'chintan-001-3B/tokenizer.json')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"chintan-001-3B\")  # Local saving\n",
        "tokenizer.save_pretrained(\"chintan-001-3B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6nNgRnt_GUb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "path = \"LLM.ipynb\"  # change if needed\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "if \"widgets\" in data.get(\"metadata\", {}):\n",
        "    del data[\"metadata\"][\"widgets\"]\n",
        "\n",
        "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "print(\"\u2705 Removed widget metadata. Re-upload this notebook to GitHub.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}